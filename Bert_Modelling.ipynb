{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwan/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-02 02:07:10.019664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 02:07:10.439340: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-02 02:07:10.601376: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-02 02:07:11.633961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-02 02:07:11.634091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-02 02:07:11.634098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "import shap\n",
    "from datasets import load_dataset\n",
    "# Just get 1000 data points and only the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train.sentence.values\n",
    "sentences_test = test.sentence.values\n",
    "y_test = test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfomer based contextual embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/TimKond/S-BioLinkBert-MedQuAD/resolve/main/vocab.txt from cache at /home/gwan/.cache/huggingface/transformers/282ac2205c2b6ee055b3dc01c0a12028a0f7d7577410e4b0f4d645ac8ad5ae2e.73b5c069d3e40205dd2df2379051c9f47d13c3bad0bcb3cee659c69e3a185a86\n",
      "loading file https://huggingface.co/TimKond/S-BioLinkBert-MedQuAD/resolve/main/tokenizer.json from cache at /home/gwan/.cache/huggingface/transformers/50f410f62d7dd7515615b2ca766bdad80a1849080838f4e92bdbf8b27e2c935f.e55b50961a3ab3d0999a4e5f18e565a07a5222dd3ad2ae9bee067fa0657a0eb0\n",
      "loading file https://huggingface.co/TimKond/S-BioLinkBert-MedQuAD/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/TimKond/S-BioLinkBert-MedQuAD/resolve/main/special_tokens_map.json from cache at /home/gwan/.cache/huggingface/transformers/5296bd60fb8c7fb94768c904e58faadd292adc943980a00515ec55a19ce721bb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/TimKond/S-BioLinkBert-MedQuAD/resolve/main/tokenizer_config.json from cache at /home/gwan/.cache/huggingface/transformers/970833cf76c5b60c0a69661ac941bc46e15eb3e3d1524d1865e0e1de0ea1ea37.e75424eaa8f45eb9f6ccee18f8f9279874ff588384ebfbea8cf68ef8475e3360\n",
      "loading configuration file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"S-BioLinkBERT-MedQuAD/final\\\\\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28895\n",
      "}\n",
      "\n",
      "loading weights file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/added_tokens.json. We won't load it.\n",
      "loading file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/vocab.txt\n",
      "loading file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/special_tokens_map.json\n",
      "loading file /home/gwan/.cache/torch/sentence_transformers/TimKond_S-BioLinkBert-MedQuAD/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"TimKond/S-BioLinkBert-MedQuAD\")\n",
    "\n",
    "model = SentenceTransformer('TimKond/S-BioLinkBert-MedQuAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprerantly Very simple embeddings clustering based on BERT does not tell anything about the sentiment\n",
    "embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_test = model.encode(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Machine learning based on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight={0:1,1:100},max_features=100,max_depth = 100)\n",
    "\n",
    "rf.fit(X = embeddings,y = train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(embeddings_test)\n",
    "rf_pred_prob = rf.predict_proba(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275862068965517"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_score(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7142857142857143, 0.9090909090909091, 0.8, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, rf_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f766c072b50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf,embeddings_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Pretrained Subjective BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/config.json from cache at /home/gwan/.cache/huggingface/transformers/bfd5c33143b50c6ac113ae1968fc7e425a16ce3742d162f9a62dfd88abf5f02f.e087ae233881216059233b1188427f7df0b885b85a39ed1731a2bcbac5c53f20\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../models/TRIAL-J-shuffle-lr_3en06-epoch_15-wd_.1-bs_32/checkpoint-67466\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"SUBJECTIVE\",\n",
      "    \"1\": \"NEUTRAL\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEUTRAL\": \"1\",\n",
      "    \"SUBJECTIVE\": \"0\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/config.json from cache at /home/gwan/.cache/huggingface/transformers/bfd5c33143b50c6ac113ae1968fc7e425a16ce3742d162f9a62dfd88abf5f02f.e087ae233881216059233b1188427f7df0b885b85a39ed1731a2bcbac5c53f20\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../models/TRIAL-J-shuffle-lr_3en06-epoch_15-wd_.1-bs_32/checkpoint-67466\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"SUBJECTIVE\",\n",
      "    \"1\": \"NEUTRAL\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEUTRAL\": \"1\",\n",
      "    \"SUBJECTIVE\": \"0\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/pytorch_model.bin from cache at /home/gwan/.cache/huggingface/transformers/5b937a1362c7b08e38c9e7af382b022e0f98174259a4e07a25211e285c67ae49.7e86f963265e884f1c1cd20ff3250851ea9bcd36999f05440f50ef2985a80fff\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at cffl/bert-base-styleclassification-subjective-neutral.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/vocab.txt from cache at /home/gwan/.cache/huggingface/transformers/177e6e9a8c46743b3e9de80bf223b971bc5d6bc7c37a692ee1646c7a8a9258b1.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/tokenizer.json from cache at /home/gwan/.cache/huggingface/transformers/5ae37e4a8af0ee6b413ce5eceae440a2bb9c55e8ba4c9a2df44d76a15d0be249.f71e12dcf3314f964e59f54247509b88c99b9eac702db689a9c4bd9444c88904\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/special_tokens_map.json from cache at /home/gwan/.cache/huggingface/transformers/684e952a92fb850f25540a65e327ab1c7d6cccff9489a03c9a66dd0b19ad9c3c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/tokenizer_config.json from cache at /home/gwan/.cache/huggingface/transformers/dc5870a44336e020056e0247d0a0474929f8f4d334dcf487520a87d87ecbc534.d6b044cdc761102e1d4ea678730ea3e9d08408790aef72f81d93f6d3077c483e\n"
     ]
    }
   ],
   "source": [
    "classify = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"cffl/bert-base-styleclassification-subjective-neutral\",\n",
    "    return_all_scores=True,tokenizer=\"cffl/bert-base-styleclassification-subjective-neutral\", max_length=512, truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "result_pretrained = classify(sentences_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert1_pred_prob = np.zeros(test.shape[0])\n",
    "for i,x in enumerate(result_pretrained):\n",
    "    bert1_pred_prob[i] = x[1]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2413793103448276"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,np.where(bert1_pred_prob > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07692307692307693, 0.09090909090909091, 0.08333333333333334, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test,np.where(bert1_pred_prob > 0.5, 1, 0), average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration .-91eede86c7e1d8a6\n",
      "Found cached dataset csv (/home/gwan/.cache/huggingface/datasets/csv/.-91eede86c7e1d8a6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "100%|██████████| 2/2 [00:00<00:00, 474.04it/s]\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"}\n",
    "dataset = load_dataset(path = './',data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "MODEL = \"cffl/bert-base-styleclassification-subjective-neutral\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/gwan/.cache/huggingface/datasets/csv/.-91eede86c7e1d8a6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-840d7e0249ecd91a.arrow\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.77ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/gwan/.cache/huggingface/datasets/csv/.-91eede86c7e1d8a6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-58ac73cdc20c4cc7.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\",\n",
    "weight_decay= 0.001,warmup_steps = 50, num_train_epochs=30,learning_rate = 1e-6,adam_epsilon = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 450\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwan19990901\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gwan/Projects/Clinical_sentiment/wandb/run-20221102_020728-2jzdec7t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wan19990901/huggingface/runs/2jzdec7t\" target=\"_blank\">test_trainer</a></strong> to <a href=\"https://wandb.ai/wan19990901/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 03:05, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.161442</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.090720</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.893359</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.821245</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.766524</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721233</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677876</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.642293</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.620946</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.587963</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.553495</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.526649</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458510</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438782</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.417741</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408394</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.390876</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.387101</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.370697</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365806</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355955</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.350827</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341951</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339768</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342172</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339471</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338608</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: index, sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 29\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.37148807101779513, metrics={'train_runtime': 194.6813, 'train_samples_per_second': 17.413, 'train_steps_per_second': 2.311, 'total_flos': 891946477670400.0, 'train_loss': 0.37148807101779513, 'epoch': 30.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()# new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running training *****\n",
      "  Num examples = 425\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwan19990901\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gwan/Projects/Clinical_sentiment/wandb/run-20221027_211613-vasvx9wb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wan19990901/huggingface/runs/vasvx9wb\" target=\"_blank\">test_trainer</a></strong> to <a href=\"https://wandb.ai/wan19990901/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 04:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606149</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436950</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.409029</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477334</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352198</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365378</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495112</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542071</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663559</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.651014</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: annotation, id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=540, training_loss=0.3172623934569182, metrics={'train_runtime': 252.8155, 'train_samples_per_second': 16.811, 'train_steps_per_second': 2.136, 'total_flos': 1118221985280000.0, 'train_loss': 0.3172623934569182, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573658</td>\n",
       "      <td>ccu nursing progress note still feel alittle n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1472567</td>\n",
       "      <td>sicu nsg note neuro ct scan head showed atroph...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>561667</td>\n",
       "      <td>title chief complaint fever tachypnea hpi 73yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>354817</td>\n",
       "      <td>altered mental status delirium assessment pati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>726477</td>\n",
       "      <td>87 female admitted er w resp distress family s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2009786</td>\n",
       "      <td>progress note 7a 7p resp ra c e mild scr rr wn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>588510</td>\n",
       "      <td>title chief complaint dyspnea 24 hour events g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>42148</td>\n",
       "      <td>admission date 2118 8 10 discharge date 2118 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>441775</td>\n",
       "      <td>chief complaint rigors 24 hour events 3 12 eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>723896</td>\n",
       "      <td>full code nkda 55 f morbid obesity htn recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text annotation  \\\n",
       "1    1573658  ccu nursing progress note still feel alittle n...          1   \n",
       "4    1472567  sicu nsg note neuro ct scan head showed atroph...          1   \n",
       "7     561667  title chief complaint fever tachypnea hpi 73yo...          1   \n",
       "11    354817  altered mental status delirium assessment pati...          1   \n",
       "12    726477  87 female admitted er w resp distress family s...          1   \n",
       "..       ...                                                ...        ...   \n",
       "519  2009786  progress note 7a 7p resp ra c e mild scr rr wn...          1   \n",
       "520   588510  title chief complaint dyspnea 24 hour events g...          1   \n",
       "523    42148  admission date 2118 8 10 discharge date 2118 8...          1   \n",
       "527   441775  chief complaint rigors 24 hour events 3 12 eve...          1   \n",
       "531   723896  full code nkda 55 f morbid obesity htn recent ...          1   \n",
       "\n",
       "     label  \n",
       "1        1  \n",
       "4        1  \n",
       "7        1  \n",
       "11       1  \n",
       "12       1  \n",
       "..     ...  \n",
       "519      1  \n",
       "520      1  \n",
       "523      1  \n",
       "527      1  \n",
       "531      1  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label[label.annotation == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573658</td>\n",
       "      <td>ccu nursing progress note still feel alittle n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1472567</td>\n",
       "      <td>sicu nsg note neuro ct scan head showed atroph...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>561667</td>\n",
       "      <td>title chief complaint fever tachypnea hpi 73yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>354817</td>\n",
       "      <td>altered mental status delirium assessment pati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>726477</td>\n",
       "      <td>87 female admitted er w resp distress family s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2009786</td>\n",
       "      <td>progress note 7a 7p resp ra c e mild scr rr wn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>588510</td>\n",
       "      <td>title chief complaint dyspnea 24 hour events g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>42148</td>\n",
       "      <td>admission date 2118 8 10 discharge date 2118 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>441775</td>\n",
       "      <td>chief complaint rigors 24 hour events 3 12 eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>723896</td>\n",
       "      <td>full code nkda 55 f morbid obesity htn recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text annotation  \\\n",
       "1    1573658  ccu nursing progress note still feel alittle n...          1   \n",
       "4    1472567  sicu nsg note neuro ct scan head showed atroph...          1   \n",
       "7     561667  title chief complaint fever tachypnea hpi 73yo...          1   \n",
       "11    354817  altered mental status delirium assessment pati...          1   \n",
       "12    726477  87 female admitted er w resp distress family s...          1   \n",
       "..       ...                                                ...        ...   \n",
       "519  2009786  progress note 7a 7p resp ra c e mild scr rr wn...          1   \n",
       "520   588510  title chief complaint dyspnea 24 hour events g...          1   \n",
       "523    42148  admission date 2118 8 10 discharge date 2118 8...          1   \n",
       "527   441775  chief complaint rigors 24 hour events 3 12 eve...          1   \n",
       "531   723896  full code nkda 55 f morbid obesity htn recent ...          1   \n",
       "\n",
       "     label  \n",
       "1        1  \n",
       "4        1  \n",
       "7        1  \n",
       "11       1  \n",
       "12       1  \n",
       "..     ...  \n",
       "519      1  \n",
       "520      1  \n",
       "523      1  \n",
       "527      1  \n",
       "531      1  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label[label.annotation == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573658</td>\n",
       "      <td>ccu nursing progress note still feel alittle n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1472567</td>\n",
       "      <td>sicu nsg note neuro ct scan head showed atroph...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>561667</td>\n",
       "      <td>title chief complaint fever tachypnea hpi 73yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>354817</td>\n",
       "      <td>altered mental status delirium assessment pati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>726477</td>\n",
       "      <td>87 female admitted er w resp distress family s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2009786</td>\n",
       "      <td>progress note 7a 7p resp ra c e mild scr rr wn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>588510</td>\n",
       "      <td>title chief complaint dyspnea 24 hour events g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>42148</td>\n",
       "      <td>admission date 2118 8 10 discharge date 2118 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>441775</td>\n",
       "      <td>chief complaint rigors 24 hour events 3 12 eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>723896</td>\n",
       "      <td>full code nkda 55 f morbid obesity htn recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text annotation  \\\n",
       "1    1573658  ccu nursing progress note still feel alittle n...          1   \n",
       "4    1472567  sicu nsg note neuro ct scan head showed atroph...          1   \n",
       "7     561667  title chief complaint fever tachypnea hpi 73yo...          1   \n",
       "11    354817  altered mental status delirium assessment pati...          1   \n",
       "12    726477  87 female admitted er w resp distress family s...          1   \n",
       "..       ...                                                ...        ...   \n",
       "519  2009786  progress note 7a 7p resp ra c e mild scr rr wn...          1   \n",
       "520   588510  title chief complaint dyspnea 24 hour events g...          1   \n",
       "523    42148  admission date 2118 8 10 discharge date 2118 8...          1   \n",
       "527   441775  chief complaint rigors 24 hour events 3 12 eve...          1   \n",
       "531   723896  full code nkda 55 f morbid obesity htn recent ...          1   \n",
       "\n",
       "     label  \n",
       "1        1  \n",
       "4        1  \n",
       "7        1  \n",
       "11       1  \n",
       "12       1  \n",
       "..     ...  \n",
       "519      1  \n",
       "520      1  \n",
       "523      1  \n",
       "527      1  \n",
       "531      1  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label[label.annotation == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573658</td>\n",
       "      <td>ccu nursing progress note still feel alittle n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1472567</td>\n",
       "      <td>sicu nsg note neuro ct scan head showed atroph...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>561667</td>\n",
       "      <td>title chief complaint fever tachypnea hpi 73yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>354817</td>\n",
       "      <td>altered mental status delirium assessment pati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>726477</td>\n",
       "      <td>87 female admitted er w resp distress family s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2009786</td>\n",
       "      <td>progress note 7a 7p resp ra c e mild scr rr wn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>588510</td>\n",
       "      <td>title chief complaint dyspnea 24 hour events g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>42148</td>\n",
       "      <td>admission date 2118 8 10 discharge date 2118 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>441775</td>\n",
       "      <td>chief complaint rigors 24 hour events 3 12 eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>723896</td>\n",
       "      <td>full code nkda 55 f morbid obesity htn recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text annotation  \\\n",
       "1    1573658  ccu nursing progress note still feel alittle n...          1   \n",
       "4    1472567  sicu nsg note neuro ct scan head showed atroph...          1   \n",
       "7     561667  title chief complaint fever tachypnea hpi 73yo...          1   \n",
       "11    354817  altered mental status delirium assessment pati...          1   \n",
       "12    726477  87 female admitted er w resp distress family s...          1   \n",
       "..       ...                                                ...        ...   \n",
       "519  2009786  progress note 7a 7p resp ra c e mild scr rr wn...          1   \n",
       "520   588510  title chief complaint dyspnea 24 hour events g...          1   \n",
       "523    42148  admission date 2118 8 10 discharge date 2118 8...          1   \n",
       "527   441775  chief complaint rigors 24 hour events 3 12 eve...          1   \n",
       "531   723896  full code nkda 55 f morbid obesity htn recent ...          1   \n",
       "\n",
       "     label  \n",
       "1        1  \n",
       "4        1  \n",
       "7        1  \n",
       "11       1  \n",
       "12       1  \n",
       "..     ...  \n",
       "519      1  \n",
       "520      1  \n",
       "523      1  \n",
       "527      1  \n",
       "531      1  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label[label.annotation == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e785c52e1a28ad980bef155e7f9c26fcc6dca216df0c4e690729e404ede1f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
