{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Guangya Wan\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "# import shap\n",
    "from datasets import load_dataset\n",
    "# Just get 1000 data points and only the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data obtained after preprocessing\n",
    "train = pd.read_csv('train.csv') \n",
    "test = pd.read_csv('test.csv')\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train.text.values\n",
    "sentences_test = test.text.values\n",
    "y_test = test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfomer based contextual embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06464b1d653d4555a788577587379fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938cf806a8094462a423b95c3c7b9b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/225k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a55d104ee94e6eaa209a9f1b939ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/447k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64557115e2144cc9165e1f85757053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_839/1837123897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TimKond/S-BioLinkBert-MedQuAD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TimKond/S-BioLinkBert-MedQuAD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"TimKond/S-BioLinkBert-MedQuAD\")\n",
    "\n",
    "model = SentenceTransformer('TimKond/S-BioLinkBert-MedQuAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprerantly Very simple embeddings clustering based on BERT does not tell anything about the sentiment\n",
    "embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_test = model.encode(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Machine learning based on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 100}, max_depth=100,\n",
       "                       max_features=100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight={0:1,1:100},max_features=100,max_depth = 100)\n",
    "\n",
    "rf.fit(X = embeddings,y = train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(embeddings_test)\n",
    "rf_pred_prob = rf.predict_proba(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896551724137931"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_score(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747474747474748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "roc_auc_score(y_score =rf_pred_prob[:,1] , y_true= y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334, 0.9090909090909091, 0.8695652173913043, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, rf_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f42306cc880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf,embeddings_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Pretrained Subjective BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/config.json from cache at /home/gwan/.cache/huggingface/transformers/bfd5c33143b50c6ac113ae1968fc7e425a16ce3742d162f9a62dfd88abf5f02f.e087ae233881216059233b1188427f7df0b885b85a39ed1731a2bcbac5c53f20\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../models/TRIAL-J-shuffle-lr_3en06-epoch_15-wd_.1-bs_32/checkpoint-67466\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"SUBJECTIVE\",\n",
      "    \"1\": \"NEUTRAL\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEUTRAL\": \"1\",\n",
      "    \"SUBJECTIVE\": \"0\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/config.json from cache at /home/gwan/.cache/huggingface/transformers/bfd5c33143b50c6ac113ae1968fc7e425a16ce3742d162f9a62dfd88abf5f02f.e087ae233881216059233b1188427f7df0b885b85a39ed1731a2bcbac5c53f20\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../models/TRIAL-J-shuffle-lr_3en06-epoch_15-wd_.1-bs_32/checkpoint-67466\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"SUBJECTIVE\",\n",
      "    \"1\": \"NEUTRAL\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEUTRAL\": \"1\",\n",
      "    \"SUBJECTIVE\": \"0\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/pytorch_model.bin from cache at /home/gwan/.cache/huggingface/transformers/5b937a1362c7b08e38c9e7af382b022e0f98174259a4e07a25211e285c67ae49.7e86f963265e884f1c1cd20ff3250851ea9bcd36999f05440f50ef2985a80fff\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at cffl/bert-base-styleclassification-subjective-neutral.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/vocab.txt from cache at /home/gwan/.cache/huggingface/transformers/177e6e9a8c46743b3e9de80bf223b971bc5d6bc7c37a692ee1646c7a8a9258b1.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/tokenizer.json from cache at /home/gwan/.cache/huggingface/transformers/5ae37e4a8af0ee6b413ce5eceae440a2bb9c55e8ba4c9a2df44d76a15d0be249.f71e12dcf3314f964e59f54247509b88c99b9eac702db689a9c4bd9444c88904\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/special_tokens_map.json from cache at /home/gwan/.cache/huggingface/transformers/684e952a92fb850f25540a65e327ab1c7d6cccff9489a03c9a66dd0b19ad9c3c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/cffl/bert-base-styleclassification-subjective-neutral/resolve/main/tokenizer_config.json from cache at /home/gwan/.cache/huggingface/transformers/dc5870a44336e020056e0247d0a0474929f8f4d334dcf487520a87d87ecbc534.d6b044cdc761102e1d4ea678730ea3e9d08408790aef72f81d93f6d3077c483e\n"
     ]
    }
   ],
   "source": [
    "classify = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"cffl/bert-base-styleclassification-subjective-neutral\",\n",
    "    return_all_scores=True,tokenizer=\"cffl/bert-base-styleclassification-subjective-neutral\", max_length=512, truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "result_pretrained = classify(sentences_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert1_pred_prob = np.zeros(test.shape[0])\n",
    "for i,x in enumerate(result_pretrained):\n",
    "    bert1_pred_prob[i] = x[1]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2413793103448276"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,np.where(bert1_pred_prob > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07692307692307693, 0.09090909090909091, 0.08333333333333334, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test,np.where(bert1_pred_prob > 0.5, 1, 0), average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Fine Tuned Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"}\n",
    "# dataset = load_dataset('csv',data_files=data_files,column_names=['text','labels'])\n",
    "from datasets import Dataset\n",
    "import datasets\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "all_dataset = Dataset.from_pandas(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "MODEL = \"cffl/bert-base-styleclassification-subjective-neutral\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ff089c19174a0db34073341c7cb013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da052d23890473bb0c9c6497bf962c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6e2018bc6c4a41b3ef4267b39303c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_all = all_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_train.shuffle(seed=42)\n",
    "small_eval_dataset = tokenized_test.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_all.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",save_strategy = 'steps', warmup_steps = 50, num_train_epochs=40,learning_rate = 5e-7,weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, index. If text, __index_level_0__, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/gwan/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 270\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1360\n",
      "  Number of trainable parameters = 109483778\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwan19990901\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gwan/Projects/Clinical_sentiment/wandb/run-20221116_112848-3byvyrph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wan19990901/huggingface/runs/3byvyrph\" target=\"_blank\">test_trainer</a></strong> to <a href=\"https://wandb.ai/wan19990901/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1360' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1360/1360 26:31, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.558100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.192400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1360, training_loss=0.30650253576390885, metrics={'train_runtime': 1603.3924, 'train_samples_per_second': 6.736, 'train_steps_per_second': 0.848, 'total_flos': 2841599397888000.0, 'train_loss': 0.30650253576390885, 'epoch': 40.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()# new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fa7c3201bb4b008a373c558285995f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▇█</td></tr><tr><td>train/global_step</td><td>▁▇█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>25.0</td></tr><tr><td>train/global_step</td><td>1125</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0467</td></tr><tr><td>train/total_flos</td><td>2321955063552000.0</td></tr><tr><td>train/train_loss</td><td>0.19018</td></tr><tr><td>train/train_runtime</td><td>534.9032</td></tr><tr><td>train/train_samples_per_second</td><td>16.498</td></tr><tr><td>train/train_steps_per_second</td><td>2.103</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">test_trainer</strong>: <a href=\"https://wandb.ai/wan19990901/huggingface/runs/2fvpsvd9\" target=\"_blank\">https://wandb.ai/wan19990901/huggingface/runs/2fvpsvd9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221109_221905-2fvpsvd9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model/config.json\n",
      "Model weights saved in model/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = 'model/'\n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e785c52e1a28ad980bef155e7f9c26fcc6dca216df0c4e690729e404ede1f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
