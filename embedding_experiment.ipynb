{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12578/3266290345.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv.gz', nrows=1000, compression='gzip',usecols=['TEXT'],\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv.gz', nrows=1000, compression='gzip',usecols=['TEXT'],\n",
    "                   error_bad_lines=False)\n",
    "# Just get 1000 data points and only the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwan/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.7'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = ['very','pleasant'] #\n",
    "pattern = '|'.join(key_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['check'] = data['TEXT'].str.contains(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     742\n",
       "False    258\n",
       "Name: check, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.check.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Admission Date:  [**2151-7-16**]       Dischar...\n",
       "1    Admission Date:  [**2118-6-2**]       Discharg...\n",
       "2    Admission Date:  [**2119-5-4**]              D...\n",
       "3    Admission Date:  [**2124-7-21**]              ...\n",
       "4    Admission Date:  [**2162-3-3**]              D...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12578/2491769875.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['TEXT'] = data.TEXT.str.replace('[^a-zA-Z1-9]', ' ') # Basic cleaning to remove *or -, can be further customized later\n"
     ]
    }
   ],
   "source": [
    "data['TEXT'] = data.TEXT.str.replace('[^a-zA-Z1-9]', ' ') # Basic cleaning to remove *or -, can be further customized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Admission Date      2151 7 16          Dischar...\n",
       "1    Admission Date      2118 6 2          Discharg...\n",
       "2    Admission Date      2119 5 4                 D...\n",
       "3    Admission Date      2124 7 21                 ...\n",
       "4    Admission Date      2162 3 3                 D...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TEXT'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Doc_to_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admission', 'date', '2151', '7', '16', 'discharge', 'date', '2151', '8', '4', 'service', 'addendum', 'radiologic', 'studies', 'radiologic', 'studies', 'also', 'included', 'a', 'chest', 'ct', 'which', 'confirmed', 'cavitary', 'lesions', 'in', 'the', 'left', 'lung', 'apex', 'consistent', 'with', 'infectious', 'process', 'tuberculosis', 'this', 'also', 'moderate', 'sized', 'left', 'pleural', 'effusion', 'head', 'ct', 'head', 'ct', 'showed', 'no', 'intracranial', 'hemorrhage', 'or', 'mass', 'effect', 'but', 'old', 'infarction', 'consistent', 'with', 'past', 'medical', 'history', 'abdominal', 'ct', 'abdominal', 'ct', 'showed', 'lesions', 'of', 't1', 'and', 'sacrum', 'most', 'likely', 'secondary', 'to', 'osteoporosis', 'these', 'can', 'be', 'followed', 'by', 'repeat', 'imaging', 'as', 'an', 'outpatient', 'first', 'name8', 'namepattern2', 'first', 'name4', 'namepattern1', '1775', 'last', 'name', 'namepattern1', 'm', 'd', 'md', 'number', '1', '1776', 'dictated', 'by', 'hospital', '18', '7', 'medquist36', 'd', '2151', '8', '5', '12', '11', 't', '2151', '8', '5', '12', '21', 'job', 'job', 'number', '18', '8']\n"
     ]
    }
   ],
   "source": [
    "sentences = data.TEXT.values\n",
    "tokenized_sent = []\n",
    "\n",
    "for s in sentences:\n",
    "    tokenized_sent.append(word_tokenize(s.lower()))\n",
    "print(tokenized_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvector_size = Dimensionality of the feature vectors.\\nwindow = The maximum distance between the current and predicted word within a sentence.\\nmin_count = Ignores all words with total frequency lower than this.\\nalpha = The initial learning rate.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d2v = Doc2Vec(tagged_data, vector_size = 200, window = 2, min_count = 10, epochs = 100)\n",
    "\n",
    "'''\n",
    "vector_size = Dimensionality of the feature vectors.\n",
    "window = The maximum distance between the current and predicted word within a sentence.\n",
    "min_count = Ignores all words with total frequency lower than this.\n",
    "alpha = The initial learning rate.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb'] = data['tokens'].apply(model_d2v.infer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>check</th>\n",
       "      <th>tokens</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission Date      2151 7 16          Dischar...</td>\n",
       "      <td>False</td>\n",
       "      <td>[admission, date, 2151, 7, 16, discharge, date...</td>\n",
       "      <td>[0.9194876, 0.31617367, 1.6602403, -0.8010895,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Date      2118 6 2          Discharg...</td>\n",
       "      <td>False</td>\n",
       "      <td>[admission, date, 2118, 6, 2, discharge, date,...</td>\n",
       "      <td>[-0.28176105, -1.3940994, 2.023058, 1.3280034,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admission Date      2119 5 4                 D...</td>\n",
       "      <td>True</td>\n",
       "      <td>[admission, date, 2119, 5, 4, discharge, date,...</td>\n",
       "      <td>[0.34921858, -1.352876, 1.4489717, 2.0817325, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admission Date      2124 7 21                 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[admission, date, 2124, 7, 21, discharge, date...</td>\n",
       "      <td>[1.0518075, -1.3964953, 0.12544218, -0.3224223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admission Date      2162 3 3                 D...</td>\n",
       "      <td>True</td>\n",
       "      <td>[admission, date, 2162, 3, 3, discharge, date,...</td>\n",
       "      <td>[-0.7803605, -0.006952791, 1.2848545, -0.52551...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  check  \\\n",
       "0  Admission Date      2151 7 16          Dischar...  False   \n",
       "1  Admission Date      2118 6 2          Discharg...  False   \n",
       "2  Admission Date      2119 5 4                 D...   True   \n",
       "3  Admission Date      2124 7 21                 ...   True   \n",
       "4  Admission Date      2162 3 3                 D...   True   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [admission, date, 2151, 7, 16, discharge, date...   \n",
       "1  [admission, date, 2118, 6, 2, discharge, date,...   \n",
       "2  [admission, date, 2119, 5, 4, discharge, date,...   \n",
       "3  [admission, date, 2124, 7, 21, discharge, date...   \n",
       "4  [admission, date, 2162, 3, 3, discharge, date,...   \n",
       "\n",
       "                                                 emb  \n",
       "0  [0.9194876, 0.31617367, 1.6602403, -0.8010895,...  \n",
       "1  [-0.28176105, -1.3940994, 2.023058, 1.3280034,...  \n",
       "2  [0.34921858, -1.352876, 1.4489717, 2.0817325, ...  \n",
       "3  [1.0518075, -1.3964953, 0.12544218, -0.3224223...  \n",
       "4  [-0.7803605, -0.006952791, 1.2848545, -0.52551...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfomer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('TimKond/S-BioLinkBert-MedQuAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.277509    0.26719996 -0.0105282  ... -0.12347386  1.0648662\n",
      "  -0.17493397]\n",
      " [ 0.03479018  0.18932167 -0.02936742 ... -0.05296332  0.73083\n",
      "  -0.21440667]\n",
      " [-0.02235499  0.33601063  0.13468382 ... -0.03416088  0.07084354\n",
      "  -0.35041183]\n",
      " ...\n",
      " [-0.1237298   0.33057767  0.28832722 ... -0.15255748  0.23030174\n",
      "  -0.4573601 ]\n",
      " [ 0.04183475  0.24472262  0.10942968 ... -0.05232212  0.44331408\n",
      "  -0.23331973]\n",
      " [-0.05767366  0.21234523  0.21282771 ...  0.09578045 -0.10990594\n",
      "  -0.38771906]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "\n",
    "def clustering_question(data,emb_col,NUM_CLUSTERS = 2):\n",
    "\n",
    "    X = np.array(data[emb_col].tolist())\n",
    "\n",
    "    kclusterer = KMeansClusterer(\n",
    "        NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance,\n",
    "        repeats=25,avoid_empty_clusters=True)\n",
    "\n",
    "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "\n",
    "    data['cluster'] = pd.Series(assigned_clusters, index=data.index)\n",
    "    data['centroid'] = data['cluster'].apply(lambda x: kclusterer.means()[x])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_d2v = clustering_question(data,'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  check\n",
       "0        False     88\n",
       "         True     610\n",
       "1        False    170\n",
       "         True     132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_d2v.groupby([\"cluster\", \"check\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb_transformer'] = data['TEXT'].apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_trans = clustering_question(data,'emb_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  check\n",
       "0        False    189\n",
       "         True     550\n",
       "1        False     69\n",
       "         True     192\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_trans.groupby([\"cluster\", \"check\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e785c52e1a28ad980bef155e7f9c26fcc6dca216df0c4e690729e404ede1f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
